% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.coxtp.r
\name{cv.coxtp}
\alias{cv.coxtp}
\title{fit a Cox Non-proportional Hazards model with P-spline or Smoothing-spline, penalization tuning parameter is provided by cross validation.}
\usage{
cv.coxtp(
  event,
  z,
  time,
  strata = NULL,
  lambda = c(0.1, 1, 10),
  nfolds = 5,
  foldid = NULL,
  penalty = "Smooth-spline",
  nsplines = 8,
  ties = "Breslow",
  tol = 1e-09,
  iter.max = 20L,
  method = "ProxN",
  gamma = 1e+08,
  btr = "dynamic",
  tau = 0.5,
  stop = "ratch",
  parallel = FALSE,
  threads = 1L,
  degree = 3L,
  fixedstep = FALSE
)
}
\arguments{
\item{event}{failure events response variable of length \code{nobs}, where \code{nobs} denotes the number of observations. It should be a vector containing 0 or 1}

\item{z}{input covariate matrix, of dimension \code{nobs} x \code{nvars}; each row is an observation vector.}

\item{time}{observed event time, should be a vector with non-negative numeric values.}

\item{strata}{stratification group defined in the data used for the stratified model.
If there exists a stratification group, please enter it as a vector.
By default, a non-stratified model would be implemented.}

\item{lambda}{a user specified sequence as the penalization coefficients in front of the spline term specified by \code{spline}.
This is the tuning parameter for penalization. Users can use \code{IC} to select the best tuning parameter based on the information criteria.
Users can specify for larger values when the estimated time-varying effects are too high.
Default is \code{0} which refers to Newton's Method without penalization.}

\item{nfolds}{number of folds - default is 5. Although nfolds can be as large as the sample size (leave-one-out CV), it is not recommended for large datasets. Smallest value allowable is nfolds=3.}

\item{foldid}{an optional vector of values between 1 and nfold identifying what fold each observation is in. If supplied, \code{nfolds} can be missing.}

\item{penalty}{a character string specifying the spline term for Penalized Newton's Method.
This term is added to the log-partial likelihood as the new objective function to control the smoothness of the time-varying covariates.
Default is \code{P-spline}. Three options are \code{P-spline}, \code{Smooth-spline} and \code{NULL}. If \code{NULL}, the method will be the same as \code{coxtv} and \code{lambda}
will be set as 0.

\code{P-spline} stands for Penalized B-spline. It combines the B-spline basis with a discrete quadratic penalty on the difference of basis coefficients between adjacent knots.
When \code{lambda} goes to infinity, the time-varying effects are encouraged to be constant.

\code{Smooth-spline} refers to the Smoothing-spline, the derivative-based penalties combined with B-splines. See \code{degree} for different choices.
When \code{degree=3}, we use the cubic B-spline penalizing the second-order derivative, which reduces to a linear term when \code{lambda} goes to infinity.
When \code{degree=2}, we use the quadratic B-spline penalizing first-order derivative, which reduces to a constant when \code{lambda} goes to infinity. See Wood (2016) for details.

If \code{P-spline} or \code{Smooth-spline}, then \code{lambda} is initialized as (0.1, 1, 10). Users can modify \code{lambda}. See details in \code{lambda}.}

\item{nsplines}{number of basis functions in the B-splines to span the time-varying effects, default value is 8.
We use the r function \code{splines::bs} to generate the B-splines.}

\item{ties}{a character string specifying the method for tie handling. If there are no tied
death times, the methods are equivalent.  By default \code{"Breslow"} uses the Breslow approximation, which can be faster when many ties occur.}

\item{tol}{convergence threshold for Newton's method. The algorithm continues until the method selected using \code{stop} converges.
The default value is  \code{1e-6}.}

\item{iter.max}{maximum Iteration number if the stopping criteria specified by \code{stop} is not satisfied. Default value is  \code{20}.}

\item{method}{a character string specifying whether to use Newton's method or Proximal Newton's method.  If \code{"Newton"} then exact hessian is used,
while default method \code{"ProxN"} implementing the proximal method which can be faster and more stable when there exists ill-conditioned second-order information of the log-partial likelihood.
See details in Wu et al. (2022).}

\item{gamma}{parameter for Proximal Newton's Method \code{"ProxN"}. The default value is \code{1e8}.}

\item{btr}{a character string specifying the backtracking line-search approach. \code{"dynamic"} is a typical way to perform backtracking line-search. See details in Convex Optimization by Boyd and Vandenberghe (2009).
\code{"static"} limits Newton's increment and can achieve more stable results in some extreme cases, such as ill-conditioned second-order information of the log-partial likelihood,
which usually occurs when some predictors are categorical with low frequency for some categories.
Users should be careful with \code{static} as this may lead to under-fitting.}

\item{tau}{a scalar in (0,1) used to control the step size inside the backtracking line-search. The default value is \code{0.5}.}

\item{stop}{a character string specifying the stopping rule to determine convergence. Use \eqn{loglik(m)} to denote the log-partial likelihood at iteration step m.
\code{"incre"} means we stop the algorithm when Newton's increment is less than the \code{tol}.
\code{"relch"} means we stop the algorithm when the \eqn{loglik(m)} divided by the  \eqn{loglik(0)} is less than the \code{tol}.
\code{"ratch"} means we stop the algorithm when \eqn{(loglik(m)-loglik(m-1))/(loglik(m)-loglik(0))} is less than the \code{tol}.
\code{"all"} means we stop the algorithm when all the stopping rules \code{"incre"}, \code{"relch"} and \code{"ratch"} is met.
Default value is \code{ratch}. If the maximum iteration steps \code{iter.max} is achieved, the algorithm stops before the stopping rule is met.}

\item{parallel}{if \code{TRUE}, then the parallel computation is enabled. The number of threads in use is determined by \code{threads}.}

\item{threads}{an integer indicating the number of threads to be used for parallel computation. Default is \code{2}. If \code{parallel} is false, then the value of \code{threads} has no effect.}

\item{degree}{degree of the piecewise polynomial for generating the B-spline basis functions---default is 3 for cubic splines.
\code{degree = 2} results in the quadratic B-spline basis functions.

If \code{penalty} is \code{Smooth-spline}, different choices of \code{degree} give different results.
When \code{degree=3}, we use the cubic B-spline penalizing the second-order derivative, which reduces to a linear term when \code{lambda} goes to infinity.
When \code{degree=2}, we use the quadratic B-spline penalizing first-order derivative, which reduces to a constant when \code{lambda} goes to infinity. See Wood (2016) for details.
Default is \code{degree=2}.}

\item{fixedstep}{if \code{TRUE}, the algorithm will be forced to run \code{iter.max} steps regardless of the stopping criterion specified.}

\item{knots}{the internal knot locations (breakpoints) that define the B-splines.
The number of the internal knots should be \code{nsplines}-\code{degree}-1.
If \code{NULL}, the locations of knots are chosen to include an equal number of events within each time interval. This choice leads to more stable results in most cases.
Users can specify the internal knot locations by themselves.}
}
\value{
an object of class \code{"cv.coxtp"} is returned, which is a list with the ingredients of the cross-validation fit.
\item{model.cv}{a \code{"coxtp"} object with tuning parameter chosen based on cross validation}
\item{lambda}{the values of \code{lambda} used in the fits.}
\item{cve}{The mean cross-validated error - a vector of length(lambda).
For the k-th testing fold (k = 1,...,\code{nfolds}), we take the remaining folds as the training folds.
Based on the model trained on the training folds, we calculate the log-partial likelihood on all the folds \eqn{loglik0} and training folds  \eqn{loglik1}.
The CVE is equal to \eqn{-2*(loglik0 - loglik1)}. This approach avoids the construction of a partial likelihood on the test set so that the risk set is always sufficiently large.}
\item{lambda.min}{Value of \code{lambda} that gives minimum cve.}
}
\description{
Fit a cox Non-proportional Hazards model via penalized maximum likelihood.
}
\details{
The function runs \code{coxtp} length of \code{lambda} x  \code{nfolds} times; each is to compute the fit with each of the folds omitted.
}
\examples{
data(ExampleData)
z <- ExampleData$x
time  <- ExampleData$time
event <- ExampleData$event
lambda  = c(0.1, 1)
fit  <- cv.coxtp(event = event, z = z, time = time, lambda=lambda, nfolds = 5)


}
\references{
Gray, R.~J.
\emph{Flexible methods for analyzing survival data using splines, with applications to breast cancer prognosis. (1992), Journal of the American Statistical Association, Vol. 87, 942--951}.
\cr

Gray, R.~J.
\emph{Spline-based tests in survival analysis. (1994), Biometrics, Vol. 50, 640--652}.
\cr

Lingfeng Luo, Kevin He, Wenbo Wu and Jeremy M.G. Taylor
\emph{Using Information Criteria to Select Smoothing Parameters when Analyzing Survival Data with Time-Varying Coefficient Hazard Models (2022)}.
\cr

Wenbo Wu, Jeremy M G Taylor, Andrew F Brouwer, Lingfeng Luo, Jian Kang, Hui Jiang and Kevin He.
\emph{Scalable proximal Methods for cause-specific hazard modeling with time-varying coefficients (2022), Lifetime Data Analysis, Vol. 28(2), 194-218}.
\cr

Wood, Simon N.
\emph{P-splines with derivative based penalties and tensor product smoothing of unevenly distributed data. (2017)
Statistics and Computing, Vol. 27(4), 985-989}.

Perperoglou, Aris, Saskia le Cessie, and Hans C. van Houwelingen.
\emph{A fast routine for fitting Cox models with time varying effects of the covariates (2006), Computer methods and programs in biomedicine, Vol. 81.2 154-161}.
\cr
}
